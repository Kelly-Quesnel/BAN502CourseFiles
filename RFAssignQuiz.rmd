# Module 4 - Assignment 3
## Kelly Quesnel
### Random Forests Assignment Quiz

#### Libraries

```{r}
library(tidyverse)
library(tidymodels)
library(caret)
library(gridExtra)
library(vip)
library(ranger)
library(randomForest)
library(skimr)
```

#### Read in and clean data

Import
```{r}
drug <- read_csv("drug_data-2.csv")
```

Name the columns
```{r}
names(drug) = c("ID", "Age", "Gender", "Education", "Country", "Ethnicity",
                "Nscore", "Escore", "Oscore", "Ascore", "Cscore", "Impulsive",
                "SS", "Alcohol", "Amphet", "Amyl", "Benzos", "Caff", "Cannabis",
                "Choc", "Coke", "Crack", "Ecstasy", "Heroin", "Ketamine", "Legalh",
                "LSD", "Meth", "Mushrooms", "Nicotine", "Semer", "VSA")
```

Change CL0 and CL1 values to "No" and others to "Yes". CL0 and CL1 indicate a drug has never been used, or was used over a decade ago. CL2 through CL6 indicate more recent drug use.
```{r}
drug[drug == "CL0"] = "No"
drug[drug == "CL1"] = "No"
drug[drug == "CL2"] = "Yes"
drug[drug == "CL3"] = "Yes"
drug[drug == "CL4"] = "Yes"
drug[drug == "CL5"] = "Yes"
drug[drug == "CL6"] = "Yes"
```

Factor conversion and recoding. Note "mutate_at" to target specific ranges of variables.
```{r}
drug_clean <- drug %>% 
  mutate_at(vars(Age:Ethnicity), 
            funs(as_factor)) %>%
  mutate(Age = factor(Age, labels = c("18_24", "25_34", "35_44", "45_54",
                                    "55_64", "65_"))) %>%
  mutate(Gender = factor(Gender, labels = c("Male", "Female"))) %>%
  mutate(Education = factor(Education, labels = c("Under16", "At16", "At17", "At18",
                                                  "SomeCollege","ProfessionalCert",
                                                  "Bachelors", "Masters",
                                                  "Doctorate"))) %>%
  mutate(Country = factor(Country, labels = c("USA", "NewZealand", "Other", "Australia",
                                              "Ireland","Canada","UK"))) %>%
  mutate(Ethnicity = factor(Ethnicity, labels = c("Black", "Asian", "White",
                                                "White/Black", "Other",
                                                "White/Asian", "Black/Asian"))) %>%
  mutate_at(vars(Alcohol:VSA), funs(as_factor)) %>%
  select(-ID)
```

Look at the clean data
```{r}
str(drug_clean)
```

We'll focus on nicotine use, so get rid of all remaining drug use variables. This is selected by alphabetical order.
```{r}
drug_clean <- drug_clean %>%
  select(!(Alcohol:Mushrooms)) %>%
  select(!(Semer:VSA))
```

#### Task 1

Check for missing data in the "drug_clean" dataframe.

Q: True/False: There is missingness in the dataset.
A: False

Code:
```{r}
skim(drug_clean)
```

#### Task 2

Split the dataset into training (70%) and testing (30%) sets. Use set.seed of 1234. Stratify by "nicotine".

Q: How many rows are in the training set?
A: 1318

Code:
```{r}
set.seed(1234)
drug_split <-
  initial_split(drug_clean, prop = 0.7, strata = Nicotine)
train <- training(drug_split)
test <- testing(drug_split)

nrow(train)
```

#### Task 3

Create appropriate visualizations (12 in all) to examine the relationships between each variable and “Nicotine”. Use grid.arrange (from the gridExtra package) to organize these visuals (perhaps in groups of four visualizations?).

Q: True/False: Individuals in the 18-24 age group are proportionally more likely to be Nicotine users than not.
A: True

Code:
```{r}
p1 <-
  ggplot(train, aes(x = Age, fill = Nicotine)) +
  geom_bar(position = "fill")
p2 <-
  ggplot(train, aes(x = Gender, fill = Nicotine)) +
  geom_bar(position = "fill")
p3 <-
  ggplot(train, aes(x = Education, fill = Nicotine)) +
  geom_bar(position = "fill")

grid.arrange(p1,p2,p3,ncol = 2)
```
```{r}
p1 <-
  ggplot(train, aes(x = Country, fill = Nicotine)) +
  geom_bar(position = "fill")
p2 <-
  ggplot(train, aes(x = Ethnicity, fill = Nicotine)) +
  geom_bar(position = "fill")

grid.arrange(p1,p2,ncol = 2)
```
```{r}
p1 <-
  ggplot(train, aes(x = Nicotine, y = Nscore)) +
  geom_boxplot()
p2 <-
  ggplot(train, aes(x = Nicotine, y = Escore)) +
  geom_boxplot()
p3 <-
  ggplot(train, aes(x = Nicotine, y = Oscore)) +
  geom_boxplot()
p4 <-
  ggplot(train, aes(x = Nicotine, y = Ascore)) +
  geom_boxplot()

grid.arrange(p1,p2,p3,p4,ncol = 2)
```
```{r}
p1 <-
  ggplot(train, aes(x = Nicotine, y = Cscore)) +
  geom_boxplot()
p2 <-
  ggplot(train, aes(x = Nicotine, y = Impulsive)) +
  geom_boxplot()
p3 <-
  ggplot(train, aes(x = Nicotine, y = SS)) +
  geom_boxplot()

grid.arrange(p1,p2,p3,ncol = 2)
```

#### Task 4

Q: True/False: Individuals with higher "impulsive" scores are more likely to be Nicotine users than not.
A: True

#### Task 5

Create a random forest model (using the ranger package) on the training set to predict Nicotine using all of the variables in the dataset. Use 5-fold, k-fold cross-validation (random number seed of 123 for the folds). Allow R to select mtry values between 2 and 8 and min_n values between 5 and 20. Use 10 levels in your “grid_regular” function. Set a random number seed of 123 for the tune_grid function. Use 100 trees.

Visualize the relationships between parameters and performance metrics.

Q: The highest accuracy in this visualization is just greater than which value? (0.725, 0.730, 0.720, 0.715)
A: 0.730

Code:

Set up folds
```{r}
set.seed(123)
rf_folds <-
  vfold_cv(train, v = 5)
```

Build RF and define parameters
```{r}
drug_recipe <- 
  recipe(Nicotine ~., train) %>%
  step_dummy(all_nominal(), -all_outcomes())

drug_model <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 100) %>%
  set_engine("ranger", importance = "permutation") %>%
  set_mode("classification")

drug_wflow <-
  workflow() %>%
  add_model(drug_model) %>%
  add_recipe(drug_recipe)

drug_grid <- grid_regular(
  mtry(range = c(2, 8)),
  min_n(range = c(5, 20)),
  levels = 10)

set.seed(123)
drug_res_tuned <- tune_grid(
  drug_wflow,
  resamples = rf_folds,
  grid = drug_grid)
```

Parameter accuracy (borrowed code from https://juliasilge.com/blog/sf-trees-random-tuning/)
```{r}
drug_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  select(mean, min_n, mtry) %>%
  pivot_longer(min_n:mtry,
    values_to = "value",
    names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "Accuracy")
```

#### Task 6

Use the best mtry and min_n values from Question 5 to finalize the workflow and fit the model to training set. Examine variable importance.

Q: Which variable is most important? (Oscore, Cscore, Impulsive, SS)
A: SS

Code:

Find best mtry and min_n
```{r}
drug_res_tuned %>%
  collect_metrics() %>%
  filter(.metric == "accuracy") %>%
  mutate(min_n = factor(min_n)) %>%
  ggplot(aes(mtry, mean, color = min_n)) +
  geom_line(alpha = 0.5, size = 1.5) +
  geom_point() +
  labs(y = "Accuracy")

# Best mtry = 6, best min_n = 16
```

Finalize fit
```{r}
best_rf <-
  select_best(drug_res_tuned, metric = "accuracy")

final_rf <-
  finalize_workflow(drug_wflow, best_rf)

final_rf
```

Fit finalized workflow to training data
```{r}
final_rf_fit <-
  fit(final_rf, train)
```

Check out variable importance
```{r}
final_rf_fit %>%
  extract_fit_parsnip() %>%
  vip(geom = "point")
```

#### Task 7

Q: To four decimal places, what is the accuracy of your model on the training set?
A: 0.9165

Code:
```{r}
trainpredrf <-
  predict(final_rf_fit, train)

head(trainpredrf)

confusionMatrix(trainpredrf$.pred_class,
                train$Nicotine,
                positive = "Yes")
```

#### Task 8

Q: To four decimal places, what is the naive accuracy (training set)?
A: 0.6707

Code:
```{r}
#Identify majority class column-wise (in this case it's "yes")
#Total the majority class column-wise, and divide by total observations

(871 + 13) / (871 + 13 + 97 + 337)
```

#### Task 9

Q: To four decimal places, what is your model’s accuracy on the testing set?
A: 0.6966

Code:
```{r}
testpredrf <-
  predict(final_rf_fit, test)

head(testpredrf)

confusionMatrix(testpredrf$.pred_class,
                test$Nicotine,
                positive = "Yes")
```

#### Task 10

Q: The difference in accuracy between the training and testing sets implies?
A: Likely overfitting. The model is extremely high accuracy in the training set (0.9165) and significantly, about 30% even, lower in the testing set (0.6966). This implies that the model was fit SO well to the training set specifically that it can only predict values in the training set. When taken outside the training set to testing or real data, it falls totally flat.

